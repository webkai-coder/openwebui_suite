# Ollama GPU Service

Startet den lokalen Ollama-Server (http://localhost:11434).
OpenWebUI verbindet sich automatisch dar√ºber.
Modelle z. B. starten mit:
```bash
ollama run mistral
